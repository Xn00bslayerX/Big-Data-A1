{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xn00bslayerX/Big-Data-A1/blob/main/assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUdpNOzgYa0Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqA15lNdb_71"
      },
      "source": [
        "# Part 1 Data Ingestion & Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH9vOGuFYmO2"
      },
      "source": [
        "Download data files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMWjSvDYpZL",
        "outputId": "c6b057b3-aa76-47b7-bdcd-92d8d272a62f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Define the URLs for the trip data and taxi zone lookup\n",
        "trip_data_file = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
        "taxi_zone = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
        "\n",
        "# Create the data/raw/ directory if it doesn't exist\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "\n",
        "# Define local filenames for the downloaded files, now within the data/raw directory\n",
        "local_trip_parquet_file = \"data/raw/yellow_tripdata_2024-01.parquet\"\n",
        "local_taxi_zone_csv_file = \"data/raw/taxi_zone_lookup.csv\"\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_file(url, local_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    with open(local_path, 'wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "\n",
        "download_file(trip_data_file, local_trip_parquet_file)\n",
        "download_file(taxi_zone, local_taxi_zone_csv_file)\n",
        "\n",
        "# Now, parse the local parquet file using polars.scan_parquet\n",
        "import polars as pl\n",
        "trip_df = pl.scan_parquet(local_trip_parquet_file)\n",
        "\n",
        "# The original cell included a `trip_df.collect()`. While `collect()` materializes the DataFrame,\n",
        "# `scan_parquet` creates a LazyFrame, which is often more efficient for chained operations.\n",
        "# We will remove `collect()` here to keep it as a LazyFrame for potential lazy evaluation benefits,\n",
        "# and only call collect when necessary (e.g., for actions like `shape`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZrJ--SDbW4w"
      },
      "source": [
        "Validate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "311c312a",
        "outputId": "106c246b-990c-42ac-b5f5-e1898300fd02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All specified columns are present in the DataFrame.\n",
            "Total number of rows: 2964624\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "\n",
        "expected_columns = [\n",
        "    'tpep_pickup_datetime',\n",
        "    'tpep_dropoff_datetime',\n",
        "    'PULocationID',\n",
        "    'DOLocationID',\n",
        "    'passenger_count',\n",
        "    'trip_distance',\n",
        "    'fare_amount',\n",
        "    'tip_amount',\n",
        "    'total_amount',\n",
        "    'payment_type'\n",
        "]\n",
        "\n",
        "# For Polars LazyFrame, use .collect_schema().names() for better performance\n",
        "actual_columns = trip_df.collect_schema().names()\n",
        "\n",
        "missing_columns = [col for col in expected_columns if col not in actual_columns]\n",
        "\n",
        "if not missing_columns:\n",
        "    print(\"All specified columns are present in the DataFrame.\")\n",
        "else:\n",
        "    print(f\"The following specified columns are missing: {', '.join(missing_columns)}\");\n",
        "    # exit or raise an error if critical columns are missing\n",
        "    exit(1)\n",
        "\n",
        "# For Polars LazyFrame, use pl.len()\n",
        "total_rows = trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Total number of rows: {total_rows}\")\n",
        "\n",
        "# Save the files to raw using Polars write_csv method\n",
        "# Note: Polars write_csv does not have an 'index' argument, as it doesn't write an index by default.\n",
        "# We need to collect the LazyFrame before writing to CSV.\n",
        "# trip_df.collect().write_csv('data/raw/trip_data.csv')\n",
        "# print(\"Trip data saved to data/raw/trip_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqyZNw02cJDe"
      },
      "source": [
        "# Part 2: Data Transformation & Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7gfum98ceSf"
      },
      "source": [
        "We need to clean the data file by removing shit data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6jMigUBciS7",
        "outputId": "1b789955-a394-4250-8552-de61ce3260ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 0 rows with null values in essential columns.\n",
            "Removed 60371 rows with non-positive trip distance.\n",
            "Removed 34539 rows with non-positive fare amount.\n",
            "Removed 30 rows with ludicrous fare amounts (above $500).\n",
            "Removed 112 rows where dropoff datetime is not after pickup datetime.\n",
            "\n",
            "Initial total rows: 2964624\n",
            "Final total rows after cleaning: 2869572\n",
            "Total rows removed: 95052\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "\n",
        "# Get initial total rows using Polars LazyFrame method\n",
        "initial_total_rows = trip_df.select(pl.len()).collect().item()\n",
        "\n",
        "# Ensure datetime columns are in the correct format for comparison later\n",
        "# For Polars LazyFrame, use with_columns and cast\n",
        "trip_df = trip_df.with_columns([\n",
        "    pl.col('tpep_pickup_datetime').cast(pl.Datetime),\n",
        "    pl.col('tpep_dropoff_datetime').cast(pl.Datetime)\n",
        "])\n",
        "\n",
        "# Remove rows with null values in essential columns\n",
        "columns_to_check_for_nulls = [\n",
        "    'tpep_pickup_datetime',\n",
        "    'tpep_dropoff_datetime',\n",
        "    'PULocationID',\n",
        "    'DOLocationID',\n",
        "    'fare_amount',\n",
        "    'tip_amount',\n",
        "    'total_amount'\n",
        "]\n",
        "\n",
        "rows_before_filter = trip_df.select(pl.len()).collect().item()\n",
        "# For Polars LazyFrame, use filter with is_not_null for each column\n",
        "trip_df = trip_df.filter(\n",
        "    pl.all_horizontal([pl.col(c).is_not_null() for c in columns_to_check_for_nulls])\n",
        ")\n",
        "removed_rows_nulls = rows_before_filter - trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Removed {removed_rows_nulls} rows with null values in essential columns.\")\n",
        "\n",
        "# Remove rows with non-positive trip distance\n",
        "rows_before_filter = trip_df.select(pl.len()).collect().item()\n",
        "trip_df = trip_df.filter(pl.col('trip_distance') > 0)\n",
        "removed_rows_distance = rows_before_filter - trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Removed {removed_rows_distance} rows with non-positive trip distance.\")\n",
        "\n",
        "# Remove rows with non-positive fare amount\n",
        "rows_before_filter = trip_df.select(pl.len()).collect().item()\n",
        "trip_df = trip_df.filter(pl.col('fare_amount') > 0)\n",
        "removed_rows_negative_fare = rows_before_filter - trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Removed {removed_rows_negative_fare} rows with non-positive fare amount.\")\n",
        "\n",
        "# Remove rows with ludicrous fare amounts (e.g., > 500)\n",
        "rows_before_filter = trip_df.select(pl.len()).collect().item()\n",
        "trip_df = trip_df.filter(pl.col('fare_amount') <= 500)\n",
        "removed_rows_ludicrous_fare = rows_before_filter - trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Removed {removed_rows_ludicrous_fare} rows with ludicrous fare amounts (above $500).\")\n",
        "\n",
        "# Remove rows where dropoff datetime is not after pickup datetime\n",
        "rows_before_filter = trip_df.select(pl.len()).collect().item()\n",
        "trip_df = trip_df.filter(pl.col('tpep_dropoff_datetime') > pl.col('tpep_pickup_datetime'))\n",
        "removed_rows_invalid_time = rows_before_filter - trip_df.select(pl.len()).collect().item()\n",
        "print(f\"Removed {removed_rows_invalid_time} rows where dropoff datetime is not after pickup datetime.\")\n",
        "\n",
        "final_rows = trip_df.select(pl.len()).collect().item()\n",
        "total_removed = initial_total_rows - final_rows\n",
        "print(f\"\\nInitial total rows: {initial_total_rows}\")\n",
        "print(f\"Final total rows after cleaning: {final_rows}\")\n",
        "print(f\"Total rows removed: {total_removed}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNwP-x16fMkQ"
      },
      "source": [
        "Now, we are going to derive columns.\n",
        "- trip_duration_minutes: calculated from pickup and dropoff timestamps\n",
        "- trip_speed_mph: distance divided by duration (handle division by zero)\n",
        "- pickup_hour: hour of day (0-23) extracted from pickup timestamp\n",
        "- pickup_day_of_week: day name (Monday-Sunday) extracted from pickuptimestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TqUcdAakfc60"
      },
      "outputs": [],
      "source": [
        "# trip_df.explain(optimized=True)\n",
        "\n",
        "# Calculate trip_duration_minutes:\n",
        "# 1. Get the duration as a Polars Duration type.\n",
        "# 2. Convert that Duration to total seconds (which is a numerical float).\n",
        "# 3. Divide by 60 to get minutes.\n",
        "trip_df = trip_df.with_columns(\n",
        "    (pl.col(\"tpep_dropoff_datetime\") - pl.col(\"tpep_pickup_datetime\")) # Result is Duration\n",
        "    .dt.total_seconds() # Result is Float64 (seconds)\n",
        "    .truediv(60) # Result is Float64 (minutes)\n",
        "    .alias(\"trip_duration_minutes\")\n",
        ")\n",
        "\n",
        "# Now, calculate trip_speed_mph using the established 'trip_duration_minutes' column\n",
        "trip_df = trip_df.with_columns(\n",
        "    (pl.col(\"trip_distance\").truediv(pl.col(\"trip_duration_minutes\")) * 60).alias(\"trip_speed_mph\")\n",
        ")\n",
        "\n",
        "# Add pickup_hour and pickup_day_of_week in a separate step\n",
        "trip_df = trip_df.with_columns(\n",
        "    pl.col(\"tpep_pickup_datetime\").dt.hour().alias(\"pickup_hour\"),\n",
        "    pl.col(\"tpep_pickup_datetime\").dt.strftime(\"%A\").alias(\"pickup_day_of_week\")\n",
        ")\n",
        "\n",
        "# The derived columns are expected to be correctly added to the LazyFrame.\n",
        "# NOTE: Removed print(trip_df.collect_schema().names()) as it was causing ColumnNotFoundError due to Polars' internal schema resolution of datetime operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFuiuVKSlmhk"
      },
      "source": [
        "Now that the cleaned Data is in polars, I will load it into DuckDB for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ475sJplrvl",
        "outputId": "95562e3e-0283-4913-c4c5-98558ff858d3"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'duckdb'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mduckdb\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Establish an in-memory DuckDB connection\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'duckdb'"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "import polars as pl\n",
        "\n",
        "# Establish an in-memory DuckDB connection\n",
        "con = duckdb.connect(database=':memory:', read_only=False)\n",
        "\n",
        "# Drop original timestamp columns right before collection\n",
        "# This ensures they are available for all derivations but removed before DuckDB sees them.\n",
        "trip_df_final = trip_df.drop(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\")\n",
        "\n",
        "# Materialize the Polars LazyFrame into a DataFrame first to resolve all lazy operations and types\n",
        "# This can be memory intensive for very large datasets, but ensures type consistency for DuckDB.\n",
        "trip_df_collected = trip_df_final.collect()\n",
        "\n",
        "# Register the collected Polars DataFrame as a view in DuckDB\n",
        "con.register('trip_data_view', trip_df_collected)\n",
        "\n",
        "# Load the taxi zone lookup CSV into DuckDB\n",
        "# 'local_taxi_zone_csv_file' variable contains the path to the downloaded CSV\n",
        "con.execute(f\"CREATE OR REPLACE VIEW lookup AS SELECT * FROM read_csv_auto('{local_taxi_zone_csv_file}');\")\n",
        "\n",
        "print(\"DuckDB connection established and Polars DataFrame 'trip_data_view' is queryable.\")\n",
        "print(f\"Taxi zone lookup data from '{local_taxi_zone_csv_file}' registered as 'lookup'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6dnxa6NmWvv"
      },
      "source": [
        "the top 10 busiest pickup zones by total number of trips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXNEVveEmacL",
        "outputId": "2b891298-6e50-4afb-fa6e-90b4a6589dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┌────────────┬──────────────┬──────────────────────────────┬───────────────────────────┐\n",
            "│ trip_count │ PULocationID │             Zone             │ percentage_of_total_trips │\n",
            "│   int64    │    int32     │           varchar            │          double           │\n",
            "├────────────┼──────────────┼──────────────────────────────┼───────────────────────────┤\n",
            "│     140141 │          161 │ Midtown Center               │        4.8836899718843085 │\n",
            "│     140118 │          237 │ Upper East Side South        │          4.88288845862728 │\n",
            "│     138427 │          132 │ JFK Airport                  │         4.823959810034388 │\n",
            "│     133962 │          236 │ Upper East Side North        │         4.668361692963271 │\n",
            "│     104342 │          162 │ Midtown East                 │         3.636152011519488 │\n",
            "│     102958 │          230 │ Times Sq/Theatre District    │        3.5879218224878136 │\n",
            "│     102152 │          186 │ Penn Station/Madison Sq West │        3.5598340100893093 │\n",
            "│     101794 │          142 │ Lincoln Square East          │        3.5473582820016363 │\n",
            "│      87693 │          138 │ LaGuardia Airport            │        3.0559609586377343 │\n",
            "│      86466 │          239 │ Upper West Side South        │        3.0132019687953466 │\n",
            "├────────────┴──────────────┴──────────────────────────────┴───────────────────────────┤\n",
            "│ 10 rows                                                                    4 columns │\n",
            "└──────────────────────────────────────────────────────────────────────────────────────┘\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = con.sql (\n",
        "    \"\"\"SELECT\n",
        "        count(*) AS trip_count,\n",
        "        PULocationID,\n",
        "        lookup.Zone,\n",
        "        (count(*) * 100.0 / (SELECT count(*) FROM trip_data_view)) AS percentage_of_total_trips\n",
        "    FROM\n",
        "        trip_data_view\n",
        "    INNER JOIN\n",
        "        lookup ON lookup.LocationID = trip_data_view.PULocationID\n",
        "    GROUP BY\n",
        "        trip_data_view.PULocationID, lookup.Zone\n",
        "    ORDER BY\n",
        "        trip_count DESC\n",
        "    LIMIT 10\"\"\"\n",
        ")\n",
        "print (result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA5aH3ki1Rpx"
      },
      "source": [
        "the average fare amount for each hour of the day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sYPozW62fxT",
        "outputId": "1c5bf611-4e15-4a65-a8eb-1ad9d291a6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┌────────────────────┬─────────────┐\n",
            "│  avg(fare_amount)  │ pickup_hour │\n",
            "│       double       │    int8     │\n",
            "├────────────────────┼─────────────┤\n",
            "│ 19.681288148659945 │           0 │\n",
            "│ 17.735780705229207 │           1 │\n",
            "│  16.62933009153335 │           2 │\n",
            "│ 18.536211857018404 │           3 │\n",
            "│ 23.451589629435443 │           4 │\n",
            "│ 27.500120061745992 │           5 │\n",
            "│  22.02714416197275 │           6 │\n",
            "│ 18.753927078437655 │           7 │\n",
            "│  17.82651547863499 │           8 │\n",
            "│  17.94713425800613 │           9 │\n",
            "│          ·         │           · │\n",
            "│          ·         │           · │\n",
            "│          ·         │           · │\n",
            "│ 19.273210301008266 │          14 │\n",
            "│  19.11408553522087 │          15 │\n",
            "│ 19.459183333604155 │          16 │\n",
            "│  18.12056111444039 │          17 │\n",
            "│  17.01523955666761 │          18 │\n",
            "│ 17.629133484352987 │          19 │\n",
            "│ 18.052625129388932 │          20 │\n",
            "│ 18.295467556211637 │          21 │\n",
            "│ 19.112202793914957 │          22 │\n",
            "│ 20.246206988836548 │          23 │\n",
            "├────────────────────┴─────────────┤\n",
            "│ 24 rows (20 shown)     2 columns │\n",
            "└──────────────────────────────────┘\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (con.sql (\n",
        "    \"select AVG(fare_amount),pickup_hour from trip_data_view group by pickup_hour\"\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe2bAptZ1WEi"
      },
      "source": [
        "percentage of trips use each payment type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-8EVC_o1kSZ",
        "outputId": "c63ccf00-f07a-40d9-e00b-bb7cde417d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┌──────────────┬──────────────┐\n",
            "│ count_star() │ payment_type │\n",
            "│    int64     │    int64     │\n",
            "├──────────────┼──────────────┤\n",
            "│       422713 │            2 │\n",
            "│       115195 │            0 │\n",
            "│      2298347 │            1 │\n",
            "│        10561 │            3 │\n",
            "│        22756 │            4 │\n",
            "└──────────────┴──────────────┘\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (con.sql (\"select count(*),payment_type from trip_data_view GROUP by payment_type\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAJ7hVEynEsk"
      },
      "source": [
        "average tip percentage (tip_amount/fare_amount) by day of week, for credit card payments only?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPsC0LuJnLQx",
        "outputId": "a5fa62ad-ec28-4c6a-92c9-34bbe1bd9aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┌─────────────────────────────────┬────────────────────┐\n",
            "│ avg((tip_amount / fare_amount)) │ pickup_day_of_week │\n",
            "│             double              │      varchar       │\n",
            "├─────────────────────────────────┼────────────────────┤\n",
            "│              0.2551411585527094 │ Monday             │\n",
            "│              0.2570662471216131 │ Wednesday          │\n",
            "│              0.2573012403104684 │ Tuesday            │\n",
            "│             0.29734457519313146 │ Thursday           │\n",
            "│             0.25101118352420015 │ Sunday             │\n",
            "│              0.2559570091258144 │ Friday             │\n",
            "│             0.26293994783252816 │ Saturday           │\n",
            "└─────────────────────────────────┴────────────────────┘\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (con.sql (\"select avg(tip_amount/fare_amount),pickup_day_of_week from trip_data_view where payment_type=1 group by pickup_day_of_week\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9KGwYYBkFLA"
      },
      "source": [
        "Most common pickup-dropoff pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSFWtf2ykICH",
        "outputId": "22a40ae7-4687-41e1-b09d-68f7b77a1ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "┌────────────┬──────────────┬───────────────────────┬──────────────┬───────────────────────┐\n",
            "│ trip_count │ PULocationID │      PickupZone       │ DOLocationID │      DropoffZone      │\n",
            "│   int64    │    int32     │        varchar        │    int32     │        varchar        │\n",
            "├────────────┼──────────────┼───────────────────────┼──────────────┼───────────────────────┤\n",
            "│      21641 │          237 │ Upper East Side South │          236 │ Upper East Side North │\n",
            "│      19199 │          236 │ Upper East Side North │          237 │ Upper East Side South │\n",
            "│      15193 │          236 │ Upper East Side North │          236 │ Upper East Side North │\n",
            "│      14112 │          237 │ Upper East Side South │          237 │ Upper East Side South │\n",
            "│      10139 │          161 │ Midtown Center        │          237 │ Upper East Side South │\n",
            "└────────────┴──────────────┴───────────────────────┴──────────────┴───────────────────────┘\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print (\n",
        "    con.sql (\"\"\"\n",
        "    SELECT\n",
        "        count(*) AS trip_count,\n",
        "        t.PULocationID,\n",
        "        plookup.Zone AS PickupZone,\n",
        "        t.DOLocationID,\n",
        "        dlookup.Zone AS DropoffZone\n",
        "    FROM\n",
        "        trip_data_view AS t\n",
        "    INNER JOIN\n",
        "        lookup AS plookup ON plookup.LocationID = t.PULocationID\n",
        "    INNER JOIN\n",
        "        lookup AS dlookup ON dlookup.LocationID = t.DOLocationID\n",
        "    GROUP BY\n",
        "        t.PULocationID, plookup.Zone, t.DOLocationID, dlookup.Zone\n",
        "    ORDER BY\n",
        "        trip_count DESC\n",
        "    LIMIT 5\n",
        "    \"\"\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMWF4ofawJUK"
      },
      "source": [
        "#Part 3: Dashboard Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYFe_qmufpR3"
      },
      "source": [
        "# AI Tools Used\n",
        "In notebook Gemini used to get code snippets.\n",
        "ChatGPT for understanding and getting conceptual knowledge\n",
        "Github Copilot for debugging"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOwIFx74jPrzErGrHMXCcOC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
